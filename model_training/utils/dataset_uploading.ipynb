{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3cdb8d-38ad-41b5-a5a9-ee70e6ddc3ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T17:49:31.833586Z",
     "iopub.status.busy": "2025-07-30T17:49:31.832125Z",
     "iopub.status.idle": "2025-07-30T18:00:24.322043Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем скачивать датасет...\n",
      "Скачано 1341.85 MiB\n",
      "Датасет скачан.\n",
      "Распаковываем датасет в /home/jupyter/datasphere/project/fire_smoke_dataset\n",
      "Готово! Данные разложены в /home/jupyter/datasphere/project/fire_smoke_dataset\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "\n",
    "base_url = 'https://cloud-api.yandex.net/v1/disk/public/resources/download?'\n",
    "public_key = 'https://disk.yandex.ru/d/6EQp8FpoaYkTwQ'\n",
    "\n",
    "# Формируем URL для получения href\n",
    "final_url = base_url + urlencode({'public_key': public_key})\n",
    "response = requests.get(final_url)\n",
    "response.raise_for_status()\n",
    "download_url = response.json()['href']\n",
    "\n",
    "# Скачиваем ZIP с прогрессом\n",
    "print(\"Начинаем скачивать датасет...\")\n",
    "r = requests.get(download_url, stream=True)\n",
    "r.raise_for_status()\n",
    "\n",
    "total_size = int(r.headers.get('content-length', 0))\n",
    "downloaded = 0\n",
    "zip_bytes = BytesIO()\n",
    "\n",
    "for chunk in r.iter_content(chunk_size=8192):\n",
    "    if not chunk:\n",
    "        continue\n",
    "    zip_bytes.write(chunk)\n",
    "    downloaded += len(chunk)\n",
    "    mb_downloaded = downloaded / (1024 * 1024)\n",
    "    print(f'\\rСкачано {mb_downloaded:.2f} MiB', end='')\n",
    "\n",
    "print()  # перенос на новую строку после прогресса\n",
    "zip_bytes.seek(0)\n",
    "print(\"Датасет скачан.\")\n",
    "\n",
    "# Путь, куда хотим распаковать датасет\n",
    "dist_path = '/home/jupyter/datasphere/project/fire_smoke_dataset'\n",
    "os.makedirs(dist_path, exist_ok=True)\n",
    "print(f\"Распаковываем датасет в {dist_path}\")\n",
    "\n",
    "# Распаковываем вручную, убирая первые два уровня папок\n",
    "with ZipFile(zip_bytes) as z:\n",
    "    for member in z.infolist():\n",
    "        parts = member.filename.split('/')\n",
    "        # Пропускаем всё, что не «глубже» двух уровней\n",
    "        if len(parts) <= 2:\n",
    "            continue\n",
    "        # Собираем путь, начиная с третьего элемента\n",
    "        relative_path = os.path.join(*parts[2:])\n",
    "        target_path = os.path.join(dist_path, relative_path)\n",
    "\n",
    "        if member.is_dir():\n",
    "            os.makedirs(target_path, exist_ok=True)\n",
    "        else:\n",
    "            os.makedirs(os.path.dirname(target_path), exist_ok=True)\n",
    "            with z.open(member) as src, open(target_path, 'wb') as dst:\n",
    "                dst.write(src.read())\n",
    "\n",
    "print(f'Готово! Данные разложены в {dist_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df623adc-deac-4bc3-8826-68bbcd3ed66f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T18:00:51.289898Z",
     "iopub.status.busy": "2025-07-30T18:00:51.288574Z",
     "iopub.status.idle": "2025-07-30T18:02:40.920104Z",
     "shell.execute_reply": "2025-07-30T18:02:40.919210Z",
     "shell.execute_reply.started": "2025-07-30T18:00:51.289829Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 0: smoke\n",
    "# 1: fire\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "\n",
    "pathDataset = '/home/jupyter/datasphere/project/fire_smoke_dataset'\n",
    "os.makedirs(f'{pathDataset}/labels', exist_ok=True)\n",
    "\n",
    "tree = ET.parse(f\"{pathDataset}/annotations.xml\")\n",
    "root = tree.getroot()\n",
    "\n",
    "nameToNumber = {'smoke': 0, 'fire': 1}\n",
    "\n",
    "cnt = 0\n",
    "for child in root:\n",
    "    if cnt < 2:\n",
    "        cnt += 1\n",
    "        continue\n",
    "\n",
    "    name = child.attrib.get('name')\n",
    "    data = ''\n",
    "    for subChild in child:\n",
    "        label = subChild.attrib.get('label')\n",
    "        x1 = subChild.attrib.get('xtl')\n",
    "        y1 = subChild.attrib.get('ytl')\n",
    "        x2 = subChild.attrib.get('xbr')\n",
    "        y2 = subChild.attrib.get('ybr')\n",
    "        bbox = [x1, y1, x2, y2]\n",
    "\n",
    "        data += str(nameToNumber[label])\n",
    "        for cord in bbox:\n",
    "            if cord != 0:\n",
    "                data = data + ' ' + str(int(float(cord))/640)\n",
    "        data += '\\n'\n",
    "    cnt += 1\n",
    "\n",
    "    with open(f'{pathDataset}/labels/{name.replace(\".jpg\", \".txt\")}', 'w') as file:\n",
    "        file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "198607c7-0ccf-4451-97ec-fe1f31fad22b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T18:02:50.100372Z",
     "iopub.status.busy": "2025-07-30T18:02:50.099075Z",
     "iopub.status.idle": "2025-07-30T18:02:58.254426Z",
     "shell.execute_reply": "2025-07-30T18:02:58.253493Z",
     "shell.execute_reply.started": "2025-07-30T18:02:50.100319Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные разбиты на train/val/test\n",
      "Проверка разбивки\n",
      "5820\n",
      "684\n",
      "342\n",
      "5820\n",
      "684\n",
      "342\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "pathDataset = '/home/jupyter/datasphere/project/fire_smoke_dataset'\n",
    "\n",
    "allFile = [f for f in os.listdir(f'{pathDataset}/labels') if f.endswith('.txt')]\n",
    "cntData = len(allFile)\n",
    "\n",
    "# разбиаение датасета\n",
    "n_test  = int(cntData * 0.05)\n",
    "n_val   = int(cntData * 0.10)\n",
    "n_train = cntData - n_test - n_val\n",
    "    \n",
    "# Разбиваем индексы\n",
    "indices = list(range(cntData))\n",
    "test_idx  = indices[:n_test]\n",
    "val_idx   = indices[n_test:n_test+n_val]\n",
    "train_idx = indices[n_test+n_val:]\n",
    "\n",
    "splits = {\n",
    "    'test':  test_idx,\n",
    "    'val':   val_idx,\n",
    "    'train': train_idx\n",
    "}\n",
    "\n",
    "# Создаём папки назначения\n",
    "for kind in ['labels', 'images']:\n",
    "    for split in ['train','val','test']:\n",
    "        os.makedirs(f'{pathDataset}/{kind}/{split}', exist_ok=True)\n",
    "\n",
    "# Перемещаем файлы по сплитам\n",
    "for split, idxs in splits.items():\n",
    "    for i in idxs:\n",
    "        name = os.path.splitext(allFile[i])[0]  # имя без .txt\n",
    "        src_lbl = f'{pathDataset}/labels/{name}.txt'\n",
    "        dst_lbl = f'{pathDataset}/labels/{split}/{name}.txt'\n",
    "        src_img = f'{pathDataset}/images/{name}.jpg'\n",
    "        dst_img = f'{pathDataset}/images/{split}/{name}.jpg'\n",
    "\n",
    "        # Move (shutil.move сам создаёт папки, но на всякий случай с)\n",
    "        shutil.move(src_lbl, dst_lbl)\n",
    "        shutil.move(src_img, dst_img)\n",
    "\n",
    "print(\"Данные разбиты на train/val/test\")\n",
    "\n",
    "print(\"Проверка разбивки\")\n",
    "for kind in ['labels', 'images']:\n",
    "    for split in ['train','val','test']:\n",
    "        a = len(os.listdir(f'{pathDataset}/{kind}/{split}'))\n",
    "        print(a)\n",
    "        \n",
    "os.remove(f'{pathDataset}/annotations.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d849285-2727-4303-bd83-1d91321227a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T16:08:41.136434Z",
     "iopub.status.busy": "2025-08-13T16:08:41.134557Z",
     "iopub.status.idle": "2025-08-13T16:08:41.320895Z",
     "shell.execute_reply": "2025-08-13T16:08:41.318569Z",
     "shell.execute_reply.started": "2025-08-13T16:08:41.136378Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cp: cannot create regular file '/home/jupyter/mnt/datasets/fire_smoke_dataset/data.yaml': Read-only file system\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Process exited with code 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2695/460068777.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexecute_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n\\nset -e\\ncp -r /home/jupyter/datasphere/project/fire_smoke_dataset/data.yaml /home/jupyter/mnt/datasets/fire_smoke_dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/kernel/lib/python3.10/site-packages/ml_kernel/script_executor.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, lang, code)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mreturn_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Process exited with code %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mreturn_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mException\u001b[0m: Process exited with code 1"
     ]
    }
   ],
   "source": [
    "#!:bash\n",
    "\n",
    "set -e\n",
    "cp -r /home/jupyter/datasphere/project/fire_smoke_dataset/* /home/jupyter/mnt/datasets/fire_smoke_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7330835-a616-4c35-8ec8-15a58b230df9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
